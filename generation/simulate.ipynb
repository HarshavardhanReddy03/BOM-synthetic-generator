{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of BoM Data for Supply Chain Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_RECORDS=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock Supply Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.supply_chain import SupplyChain, LeafNode, CombinerNode, SinkNode\n",
    "\n",
    "def create_supply_chain():\n",
    "    supply_chain = SupplyChain()\n",
    "\n",
    "    # Create leaf nodes with random cost types\n",
    "    leaf1 = LeafNode(200, \"raw_material_1\", [(0, 10), (5, 15), (10, 20)], random.choice([\"fixed\", \"positive_dynamic\", \"negative_dynamic\"]))\n",
    "    leaf2 = LeafNode(250, \"raw_material_2\", [(0, 15), (5, 20), (10, 25)], random.choice([\"fixed\", \"positive_dynamic\", \"negative_dynamic\"]))\n",
    "    leaf3 = LeafNode(220, \"raw_material_3\", [(0, 12), (5, 18), (10, 22)], random.choice([\"fixed\", \"positive_dynamic\", \"negative_dynamic\"]))\n",
    "    supply_chain.add_node(leaf1)\n",
    "    supply_chain.add_node(leaf2)\n",
    "    supply_chain.add_node(leaf3)\n",
    "\n",
    "    # Create intermediate nodes with random cost types\n",
    "    intermediate_a1 = CombinerNode(300, \"intermediate_a1\", [0.8, 1.0], [1, 1.2], random.choice([\"fixed\", \"positive_dynamic\", \"negative_dynamic\"]))\n",
    "    intermediate_a2 = CombinerNode(280, \"intermediate_a2\", [0.9, 1.1], [1.1, 1.3], random.choice([\"fixed\", \"positive_dynamic\", \"negative_dynamic\"]))\n",
    "    supply_chain.add_node(intermediate_a1)\n",
    "    supply_chain.add_node(intermediate_a2)\n",
    "\n",
    "    intermediate_b1 = CombinerNode(300, \"intermediate_b1\", [0.8, 1.0], [1, 1.2], random.choice([\"fixed\", \"positive_dynamic\", \"negative_dynamic\"]))\n",
    "    intermediate_b2 = CombinerNode(280, \"intermediate_b2\", [0.9, 1.1], [1.1, 1.3], random.choice([\"fixed\", \"positive_dynamic\", \"negative_dynamic\"]))\n",
    "    supply_chain.add_node(intermediate_b1)\n",
    "    supply_chain.add_node(intermediate_b2)\n",
    "\n",
    "    # Create final combiner node with random cost type\n",
    "    final_combiner = CombinerNode(350, \"final_product\", [0.7, 0.8, 0.9], [1, 1.1, 1.2], random.choice([\"fixed\", \"positive_dynamic\", \"negative_dynamic\"]))\n",
    "    supply_chain.add_node(final_combiner)\n",
    "\n",
    "    # Create sink node with random cost type\n",
    "    sink = SinkNode(consumption_rate=250, cost_type=random.choice([\"fixed\", \"positive_dynamic\", \"negative_dynamic\"]))\n",
    "    supply_chain.add_node(sink)\n",
    "\n",
    "    # Add edges with cost ranges\n",
    "    supply_chain.add_edge(leaf1, intermediate_a1, 10, 30, 5, 15)\n",
    "    supply_chain.add_edge(leaf2, intermediate_a1, 15, 35, 8, 20)\n",
    "    supply_chain.add_edge(leaf2, intermediate_a2, 12, 30, 6, 18)\n",
    "    supply_chain.add_edge(leaf3, intermediate_a2, 14, 32, 7, 19)\n",
    "    supply_chain.add_edge(intermediate_a1, intermediate_b1, 20, 40, 10, 25)\n",
    "    supply_chain.add_edge(intermediate_a2, intermediate_b1, 22, 42, 11, 27)\n",
    "    supply_chain.add_edge(intermediate_b1, final_combiner, 20, 40, 10, 25)\n",
    "    supply_chain.add_edge(intermediate_b2, final_combiner, 22, 42, 11, 27)\n",
    "    supply_chain.add_edge(leaf3, final_combiner, 18, 35, 9, 23)\n",
    "    supply_chain.add_edge(final_combiner, sink, 25, 50, 13, 30)\n",
    "\n",
    "    return supply_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation\n",
    "time = 0\n",
    "supply_chain = create_supply_chain()\n",
    "\n",
    "for _ in range(200):  # Simulate for 200 time steps\n",
    "    supply_chain.update()\n",
    "    time += 1\n",
    "\n",
    "    # Print current state\n",
    "    print(f\"Time: {time}\")\n",
    "    for node in supply_chain.nodes:\n",
    "        print(f\"Node ({node.node_class}): Inventory = {node.inventory}, Last Production = {node.last_production}, Cost Type = {node.cost_type}\")\n",
    "        for edge, target_node in node.outgoing_edges:\n",
    "            print(f\"  Edge to {target_node.node_class}: Quantity = {edge.quantity}, Cost = {edge.current_cost:.2f}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recording of the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_and_collect_data(supply_chain, n_cycles):\n",
    "    # Initialize DataFrames\n",
    "    metadata = []\n",
    "    node_data = []\n",
    "    edge_data = []\n",
    "    \n",
    "    node_id = 0\n",
    "\n",
    "    # Create metadata and assign unique IDs\n",
    "    for node in supply_chain.nodes:\n",
    "        metadata.append({\n",
    "            'node_id': f\"node_{node_id}\",\n",
    "            'node_class': node.node_class,\n",
    "            'max_inventory': node.max_inventory,\n",
    "            'cost_type': node.cost_type\n",
    "        })\n",
    "        node.id = node_id  # Assign ID to node object for reference\n",
    "        node_id += 1\n",
    "\n",
    "    edge_id = 0\n",
    "    # Create edge metadata\n",
    "    for edge in supply_chain.edges:\n",
    "        source_node = None\n",
    "        target_node = None\n",
    "        \n",
    "        for node in supply_chain.nodes:\n",
    "            if edge in [e for e, _ in node.outgoing_edges]:\n",
    "                source_node = node\n",
    "            if edge in [e for e, _ in node.incoming_edges]:\n",
    "                target_node = node\n",
    "            if source_node and target_node:\n",
    "                break\n",
    "        \n",
    "        if not source_node or not target_node:\n",
    "            print(f\"Warning: Edge {edge_id} is not properly connected.\")\n",
    "            print(f\"Source node: {source_node.node_class if source_node else 'None'}\")\n",
    "            print(f\"Target node: {target_node.node_class if target_node else 'None'}\")\n",
    "            continue\n",
    "        \n",
    "        metadata.append({\n",
    "            'edge_id': f\"edge_{edge_id}\",\n",
    "            'source_node_id': source_node.id,\n",
    "            'target_node_id': target_node.id,\n",
    "            'unit_price': edge.unit_price,\n",
    "            'min_cost': edge.min_cost,\n",
    "            'max_cost': edge.max_cost\n",
    "        })\n",
    "        edge.id = edge_id  # Assign ID to edge object for reference\n",
    "        edge_id += 1\n",
    "\n",
    "    # Simulate for n cycles\n",
    "    for cycle in range(n_cycles):\n",
    "        supply_chain.update()\n",
    "\n",
    "        # Collect node data\n",
    "        for node in supply_chain.nodes:\n",
    "            node_data.append({\n",
    "                'cycle': cycle,\n",
    "                'node_id': f\"node_{node.id}\",\n",
    "                'inventory': node.inventory,\n",
    "                'last_production': node.last_production\n",
    "            })\n",
    "\n",
    "        # Collect edge data\n",
    "        for edge in supply_chain.edges:\n",
    "            if hasattr(edge, 'id'):  # Only collect data for edges that were properly connected\n",
    "                edge_data.append({\n",
    "                    'cycle': cycle,\n",
    "                    'edge_id': f\"edge_{edge.id}\",\n",
    "                    'quantity': edge.quantity,\n",
    "                    'current_cost': edge.current_cost\n",
    "                })\n",
    "\n",
    "    # Create DataFrames\n",
    "    metadata_df = pd.DataFrame(metadata)\n",
    "    node_data_df = pd.DataFrame(node_data)\n",
    "    edge_data_df = pd.DataFrame(edge_data)\n",
    "\n",
    "    return metadata_df, node_data_df, edge_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supply_chain = create_supply_chain()\n",
    "metadata_df, node_data_df, edge_data_df = simulate_and_collect_data(supply_chain, n_cycles=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion between JSON and DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "def dataframes_to_json(metadata: pd.DataFrame, node: pd.DataFrame, edge: pd.DataFrame) -> str:\n",
    "    bom = {\n",
    "        \"metadata\": metadata.to_dict(orient='records'),\n",
    "        \"nodes\": {},\n",
    "        \"edges\": {}\n",
    "    }\n",
    "\n",
    "    # Process node data\n",
    "    for _, row in node.iterrows():\n",
    "        node_id = row['node_id']\n",
    "        cycle = row['cycle']\n",
    "        if node_id not in bom[\"nodes\"]:\n",
    "            bom[\"nodes\"][node_id] = {}\n",
    "        bom[\"nodes\"][node_id][cycle] = row.to_dict()\n",
    "\n",
    "    # Process edge data\n",
    "    for _, row in edge.iterrows():\n",
    "        edge_id = row['edge_id']\n",
    "        cycle = row['cycle']\n",
    "        if edge_id not in bom[\"edges\"]:\n",
    "            bom[\"edges\"][edge_id] = {}\n",
    "        bom[\"edges\"][edge_id][cycle] = row.to_dict()\n",
    "\n",
    "    return json.dumps(bom, indent=2)\n",
    "\n",
    "def json_to_dataframes(json_data: str) -> Dict[str, pd.DataFrame]:\n",
    "    bom = json.loads(json_data)\n",
    "\n",
    "    # Create empty lists to store the data\n",
    "    node_data = []\n",
    "    edge_data = []\n",
    "\n",
    "    # Process nodes\n",
    "    for node_id, cycles in bom[\"nodes\"].items():\n",
    "        for cycle, node_info in cycles.items():\n",
    "            node_data.append(node_info)\n",
    "\n",
    "    # Process edges\n",
    "    for edge_id, cycles in bom[\"edges\"].items():\n",
    "        for cycle, edge_info in cycles.items():\n",
    "            edge_data.append(edge_info)\n",
    "\n",
    "    # Create DataFrames\n",
    "    metadata_df = pd.DataFrame(bom[\"metadata\"])\n",
    "    node_df = pd.DataFrame(node_data)\n",
    "    edge_df = pd.DataFrame(edge_data)\n",
    "\n",
    "    return {\n",
    "        \"metadata\": metadata_df,\n",
    "        \"node\": node_df,\n",
    "        \"edge\": edge_df\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframes to JSON\n",
    "json_string = dataframes_to_json(metadata_df, node_data_df, edge_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.loads(json_string)\n",
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_RECORDS:\n",
    "    with open('../data/json/true.json', 'w') as f:\n",
    "        json.dump(json_data, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert JSON back to dataframes\n",
    "reconstructed_dfs = json_to_dataframes(json_string)\n",
    "\n",
    "# Access the reconstructed dataframes\n",
    "reconstructed_metadata = reconstructed_dfs['metadata']\n",
    "reconstructed_node = reconstructed_dfs['node']\n",
    "reconstructed_edge = reconstructed_dfs['edge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_RECORDS:\n",
    "    reconstructed_metadata.to_csv('../data/csv/metadata.csv', index=False)\n",
    "    reconstructed_node.to_csv('../data/csv/node.csv', index=False)\n",
    "    reconstructed_edge.to_csv('../data/csv/edge.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_edge "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggredation of Cycles and Conversion between JSON and Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def aggregated_dataframes_to_json(metadata: pd.DataFrame, node: pd.DataFrame, edge: pd.DataFrame, max_aggregation_cycles: int = 3) -> str:\n",
    "    bom = {\n",
    "        \"metadata\": metadata.to_dict(orient='records'),\n",
    "        \"nodes\": {},\n",
    "        \"edges\": {}\n",
    "    }\n",
    "\n",
    "    # Initialize variables to track the last cycle\n",
    "    last_node_cycle = 0\n",
    "    last_edge_cycle = 0\n",
    "    \n",
    "    num_cycles_to_aggregate = random.randint(1, max_aggregation_cycles)\n",
    "\n",
    "    # Process node data with aggregation\n",
    "    for _, row in node.iterrows():\n",
    "        node_id = row['node_id']\n",
    "        cycle = row['cycle']\n",
    "        # Check if we can aggregate\n",
    "        if node_id not in bom[\"nodes\"]:\n",
    "            bom[\"nodes\"][node_id] = {}\n",
    "        \n",
    "        # Aggregate nodes\n",
    "        for _ in range(num_cycles_to_aggregate):\n",
    "            last_node_cycle += 1\n",
    "            # Create a new entry for the aggregated node\n",
    "            aggregated_node = row.copy()\n",
    "            aggregated_node['cycle'] = last_node_cycle\n",
    "            bom[\"nodes\"][node_id][last_node_cycle] = aggregated_node.to_dict()\n",
    "\n",
    "    # Process edge data with aggregation\n",
    "    for _, row in edge.iterrows():\n",
    "        edge_id = row['edge_id']\n",
    "        cycle = row['cycle']\n",
    "        # Check if we can aggregate\n",
    "        if edge_id not in bom[\"edges\"]:\n",
    "            bom[\"edges\"][edge_id] = {}\n",
    "        \n",
    "        # Aggregate edges\n",
    "        for _ in range(num_cycles_to_aggregate):\n",
    "            last_edge_cycle += 1\n",
    "            # Create a new entry for the aggregated edge\n",
    "            aggregated_edge = row.copy()\n",
    "            aggregated_edge['cycle'] = last_edge_cycle\n",
    "            bom[\"edges\"][edge_id][last_edge_cycle] = aggregated_edge.to_dict()\n",
    "\n",
    "    return json.dumps(bom, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_json = aggregated_dataframes_to_json(metadata_df, node_data_df, edge_data_df)\n",
    "aggregated_json_dict = json.loads(aggregated_json)\n",
    "\n",
    "aggregated_json_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_RECORDS:\n",
    "    import json\n",
    "    with open('../data/json/aggregated.json', 'w') as f:\n",
    "        json.dump(aggregated_json_dict, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_dataframe = json_to_dataframes(aggregated_json)\n",
    "\n",
    "aggregated_metadata = aggregated_dataframe[\"metadata\"]\n",
    "aggregated_nodes = aggregated_dataframe[\"node\"]\n",
    "aggregated_edges = aggregated_dataframe[\"edge\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_RECORDS:\n",
    "    aggregated_metadata.to_csv(\"../data/csv/aggregated_metadata.csv\", index=False)\n",
    "    aggregated_nodes.to_csv(\"../data/csv/aggregated_node_data.csv\", index=False)\n",
    "    aggregated_edges.to_csv(\"../data/csv/aggregated_edge_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_edges"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
